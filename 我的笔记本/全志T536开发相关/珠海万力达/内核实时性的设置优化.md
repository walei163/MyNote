# Linux内核实时性的设置和优化

## 2026-01-29：

今天又看到一篇文章，**在应用层实时性还可以做以下优化**：

作者：程序员良许
链接：https://www.zhihu.com/question/20610026/answer/1998059625019375660
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。



### 1、把关键任务绑核

Linux是多核的，但默认调度器会把任务在不同核心间搬来搬去。这个过程本身就有延迟。

我的做法是，把实时任务绑定到某个核心，其他核心跑非实时任务。这样实时任务就不会被打扰。

用`taskset`命令就能搞定，或者在代码里调用`sched_setaffinity`。

### 2、锁内存

Linux的内存管理会换页，这对实时性是灾难。

解决办法是用`mlockall`把进程的内存全锁住，不让内核换页。

```c
mlockall(MCL_CURRENT | MCL_FUTURE);
```

这一行代码，能让你的实时性提升一个档次。

copilot给出一个示例：

```c
#include <sys/mman.h>
#include <stdio.h>
#include <string.h>
#include <errno.h>

int main(void) {
    if (mlockall(MCL_CURRENT | MCL_FUTURE) != 0) {
        fprintf(stderr, "mlockall failed: %s\n", strerror(errno));
        return 1;
    }

    // 业务逻辑
    printf("memory locked\n");

    // 可选：释放锁定
    munlockall();
    return 0;
}
```

> [!important]
>
> `mlockall(MCL_CURRENT | MCL_FUTURE)` 用于将进程的当前内存页和未来新分配的内存页锁定在物理内存中，防止被换出到 swap，从而降低实时性抖动和缺页延迟。常用于实时/低延迟程序，但需要相应权限（通常需要 `CAP_IPC_LOCK` 或足够的 `RLIMIT_MEMLOCK`）。
>
> 要点：
>
> - `MCL_CURRENT`：锁定当前已映射内存。
> - `MCL_FUTURE`：锁定未来 malloc/mmap 等新增内存。
> - 失败常见原因：权限不足或 `RLIMIT_MEMLOCK` 太小。

---

**如果因为权限不足或 `RLIMIT_MEMLOCK` 太小，该如何改进呢？**

> [!note]
>
> 可行的改进手段有三类（按常见性）：
>
> **1、提升 RLIMIT_MEMLOCK（每进程可锁定内存上限）**
>
> - 临时：ulimit -l unlimited（或设为更大数值）
> - 永久：在 limits.conf 里为用户设置：
>
> ```sh
> <user> soft memlock unlimited
> <user> hard memlock unlimited
> ```
>
> 或指定具体 KB 上限（例如 262144 表示 256MB）。之后重新登录生效。
>
> **2、赋予进程 CAP_IPC_LOCK 能力（无需 root 即可锁定更大内存）**
>
> - 给可执行文件加能力：
>
> ```sh
> sudo setcap cap_ipc_lock=+ep /path/to/your_app
> ```
>
> - 或通过 systemd 服务添加 ：`CapabilityBoundingSet=CAP_IPC_LOCK`
>
> **3、用 systemd 运行时设置**
>
> - 在服务文件里：
>
> ```ini
> [Service]
> LimitMEMLOCK=infinity
> ```
>
> 或设为具体字节数（例如 LimitMEMLOCK=268435456）。
>
> **4、补充：**
>
> 仅需要锁定关键缓冲区时可用 `mlock()` 替代 `mlockall()`，减少对上限的需求。
> 如果是在容器里，还要关注容器的 `ulimit` 和 `--cap-add=IPC_LOCK` 设置。

---

### 3、提高任务优先级

Linux支持实时调度策略，比如`SCHED_FIFO`和`SCHED_RR`。

我一般用`SCHED_FIFO`，优先级设到：**99（最高）**。这样实时任务就能抢占其他所有任务。

```c
struct sched_param param;
param.sched_priority = 99;
sched_setscheduler(0, SCHED_FIFO, &param);
```

但是注意，优先级太高也有风险。如果你的实时任务写得有bug，死循环了，整个系统都会卡死。

### 4、优化中断处理

中断处理要快，能放到线程里做的就别在中断里做。

Linux有个机制叫线程化中断**（threaded IRQ）**，可以把中断下半部放到内核线程里执行。这样中断处理函数就能保持很短。

我在驱动里用了`request_threaded_irq`，中断响应时间从几百微秒降到了几十微秒。

### 5、关闭不必要的服务

Linux默认会跑一堆后台服务，比如日志、网络管理、桌面环境等等。这些都会抢占CPU。

我的做法是，把不需要的服务全关掉，只保留最基本的。

用`systemctl disable`命令，或者直接改启动脚本。

### 6、用[实时内核](https://zhida.zhihu.com/search?content_id=766659165&content_type=Answer&match_order=1&q=实时内核&zhida_source=entity)

如果`PREEMPT_RT`还不够，可以考虑用专门的实时Linux发行版，比如[Xenomai](https://zhida.zhihu.com/search?content_id=766659165&content_type=Answer&match_order=1&q=Xenomai&zhida_source=entity)或[RTAI](https://zhida.zhihu.com/search?content_id=766659165&content_type=Answer&match_order=1&q=RTAI&zhida_source=entity)。

这些方案是在Linux内核旁边跑一个实时内核，实时任务由实时内核调度，非实时任务由Linux调度。

我在汽车电子项目里用过Xenomai，实时性确实牛逼，微秒级的响应没问题。但是学习曲线陡，而且生态没有标准Linux丰富。

---

## 1、修改uboot启动参数：

2025-08-27：uboot启动参数修改：

```sh
fw_setenv setargs_mmc 'setenv  bootargs earlyprintk=${earlyprintk} initcall_debug=${initcall_debug} console=${console} loglevel=${loglevel} root=${mmc_root} rootwait init=${init} rdinit=${rdinit} partitions=${partitions} cma=${cma} snum=${snum} mac_addr=${mac} wifi_mac=${wifi_mac} bt_mac=${bt_mac} selinux=${selinux} specialstr=${specialstr} coherent_pool=${coherent_pool} ion_carveout_list=${reserve_list} gpt=1 idle=poll nohz_full=2,3 isolcpus=2,3 rcu_nocbs=2,3'
```

- 将`idle`改为：poll

- 将`nohz_full`改为：2,3

- 将`isolcpus`改为：2,3

- 将`rcu_nocbs`改为：2,3

---

```sh
fw_setenv setargs_mmc 'setenv  bootargs earlyprintk=${earlyprintk} initcall_debug=${initcall_debug} console=${console} loglevel=${loglevel} root=${mmc_root} rootwait init=${init} rdinit=${rdinit} partitions=${partitions} cma=${cma} snum=${snum} mac_addr=${mac} wifi_mac=${wifi_mac} bt_mac=${bt_mac} selinux=${selinux} specialstr=${specialstr} coherent_pool=${coherent_pool} ion_carveout_list=${reserve_list} gpt=1 idle=poll nohz_full=2,3 isolcpus=2,3 rcu_nocbs=2,3'
```

其中，重要的是：

- idle=poll：不让内核进入idle状态；
- nohz_full=3：表示在CPU3运行实时任务时，不会因为CPU的定时器中断而被打算实时任务的运行。
- isolcpus=3：表示可以在cmdline中直接将CPU3隔离出来给实时进程使用。
- rcu_nocbs=2,3：表示不让rcu回调调度到其它CPU上。
- 如果想要隔离多个CPU，写法如下（例如隔离CPU1和CPU2）：

```sh
isolcpus=1,2 nohz_full=1,2
```

**注意：**

**`nohz_full`需要重新编译内核：**

```sh
General setup  ---> 
	Timers subsystem  --->
		Timer tick handling (Full dynticks system (tickless))  ---> 
        	 (X) Full dynticks system (tickless)
			
```

内核默认编译为：

```sh
Timer tick handling (Idle dynticks system (tickless idle))  --->
	(X) Idle dynticks system (tickless idle)
```

如果内核没有编译为：tickless模式，则内核启动时会打印：

```sh
[    0.000000] Housekeeping: nohz unsupported. Build with CONFIG_NO_HZ_FULL
```

重新编译内核启动后，如果设置成功，内核会打印：

```sh
# dmesg |grep NO_HZ
[    0.000000] NO_HZ: Full dynticks CPUs: 3.
```

此时查看内核中断信息，发现CPU3上没有中断调度了：

```sh
# cat /proc/interrupts 
           CPU0       CPU1       CPU2       CPU3       
 11:     232957       2353       3515        257     GICv3  27 Level     arch_timer
 13:          0          0          0          0     GICv3  87 Level     timer@3008000
 26:          0          0          0          0  wakeupgen  65 Level     2010000.iommu
 43:          0          0          0          0     GICv3  23 Level     arm-pmu
 45:       4757          0          0          0  wakeupgen   2 Level     uart-ng0
 53:          0          0          0          0  wakeupgen 159 Level     sunxi-rtp
 54:         33          0          0          0  wakeupgen  42 Level     mmc2
 56:          0          0          0          0  wakeupgen  66 Level     sunxikbd
 57:       1395          0          0          0  wakeupgen  40 Level     mmc0
 59:          0          0          0          0  wakeupgen  50 Level     3001000.dma-controller
 60:          0          0          0          0  wakeupgen 235 Level     3001000.dma-controller
 61:          0          0          0          0  wakeupgen 164 Level     4000000.dma-controller
 62:          0          0          0          0  wakeupgen 236 Level     4000000.dma-controller
 63:          0          0          0          0  wakeupgen  64 Level     sunxi-gpadc
 64:          0          0          0          0  wakeupgen  62 Level     sunxi-gpadc
 65:          0          0          0          0  wakeupgen 158 Level     sunxi-gpadc
 66:         60          0          0          0  wakeupgen 207 Level     7083000.twi
 67:          2          0          0          0  wakeupgen  10 Level     2510000.twi
 68:          3          0          0          0  wakeupgen  16 Level     4025000.spi
 69:          0          0          0          0  wakeupgen  21 Level     4028000.spi
 70:          0          0          0          0  wakeupgen  22 Level     4029000.spi
 71:          0          0          0          0  wakeupgen   0 Level     3003000.msgbox
 72:          0          0          0          0  wakeupgen 215 Level     3003000.msgbox
 73:          0          0          0          0  wakeupgen 183 Level     3003000.msgbox
 74:          0          0          0          0  wakeupgen 166 Level     3600000.msgbox_core0
 75:          0          0          0          0  wakeupgen 170 Level     3600000.msgbox_core0
 76:          0          0          0          0  wakeupgen 171 Level     3600000.msgbox_core0
 77:          0          0          0          0  wakeupgen 172 Level     3600000.msgbox_core0
 80:          0          0          0          0  wakeupgen  19 Level     pwm
 84:      15162          0          0          0  wakeupgen  32 Level     ehci_hcd:usb1
 85:          0          0          0          0  wakeupgen  33 Level     ohci_hcd:usb2
 87:          0          0          0          0  wakeupgen 143 Level     5440000.g2d
 88:          0          0          0          0  wakeupgen 120 Level     cedar_dev
155:          1          0          0          0  sunxi-8i-nmi   0 Level     axp2202_irq_chip
360:          0          0          0          0  sunxi_pio_edge 166 Edge      4020000.sdmmc cd
IPI0:        38         83        105          9       Rescheduling interrupts
IPI1:       291        517        654          8       Function call interrupts
IPI2:         0          0          0          0       CPU stop interrupts
IPI3:         0          0          0          0       CPU stop (for crash dump) interrupts
IPI4:         0          0          0          0       Timer broadcast interrupts
IPI5:         0          0          0          2       IRQ work interrupts
IPI6:         0          0          0          0       CPU wake-up interrupts
Err:          0
```



---

## 2、设置实时中断：

按照第1节描述设置号内核后，就可以将实时中断直接绑定到那个被隔离出来的CPU3上。例如上节中断列表中45号中断为uart-ng0，我们将这个中断绑定到隔离的CPU3上：

```sh
echo 8 > /proc/irq/45/smp_affinity
```

> 其中：
>
> 8：表示将中断指定到CPU3上，按照“按位与“的模式，1（b01）表示CPU0，2（b10）表示CPU1，8（b1000）表示CPU3。3（b11）表示中断在两个CPU上都可以运行。
>
> 45：表示欲要设置的中断号。

设置成功后，可以查看中断情况：

```sh
# watch -n1 cat /proc/interrupts |grep uart-ng0
 45:       9502          0          0      25648  wakeupgen   2 Level     uart-ng0
 45:       9502          0          0      25651  wakeupgen   2 Level     uart-ng0
 45:       9502          0          0      25654  wakeupgen   2 Level     uart-ng0
 45:       9502          0          0      25657  wakeupgen   2 Level     uart-ng0
 45:       9502          0          0      25660  wakeupgen   2 Level     uart-ng0
 45:       9502          0          0      25663  wakeupgen   2 Level     uart-ng0
 45:       9502          0          0      25666  wakeupgen   2 Level     uart-ng0
 45:       9502          0          0      25669  wakeupgen   2 Level     uart-ng0
 45:       9502          0          0      25672  wakeupgen   2 Level     uart-ng0
 45:       9502          0          0      25675  wakeupgen   2 Level     uart-ng0
 45:       9502          0          0      25678  wakeupgen   2 Level     uart-ng0
```

可以看到，45号中断只在CPU3上产生。

## 3、设置实时进程：

```sh
taskset -c 3 ./bind_core
```

或者

```sh
taskset 0x08 ./bind_core
```

> -c 3：以CPU list方式显示并指定在哪个CPU上运行。此处表示在CPU3上运行。
>
> 如果是多个，则写法为：-c 2, 3
>
> 0x08：CPU位掩码，8表示1000，也就是CPU3。

运行结果：

```sh
# taskset 0x8 ./bind_core
Testing CPU ability...
a:139079893     b:139106463
Test completed.
```

如果是已经运行的进程，则设置方式是要该进程的PID。例如：

```sh
taskset -pc 0,3,7-11 700
```

## 4、查看进程被CPU绑定运行的状态

用TF卡启动后，可以运行`htop`命令：

![](/home/jason/BaiduSyncdisk/VNote笔记本_20200401/我的笔记本/全志T536开发相关/珠海万力达/屏幕截图 2025-08-27 162355.png)


可以看到，该命令可以显示4路CPU的当前运行状态。结合第3节的`bind_core`测试命令，可以实时测试CPU资源占用的状态，最大可以被占满100%资源。

